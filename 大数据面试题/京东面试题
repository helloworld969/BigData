学长一：
  自我介绍，介绍一下你们的数仓部分
  1.如何保证hdfs的数据load到ods层，数据不丢失？ 直接把数据干掉，用sqoop脚本把指定表的数据重跑一边。
  2.采集过程如何保证数据不丢失？  flume断点续传、file channel，kafka多副本等机制、ack=-1 
  3.presto讲一讲
  4.superset讲一讲
  5.离线用的是spark引擎还是mr引擎？ 
  6.spark遇到过哪些问题？
  7.spark对小文件的处理？   通过repartition或coalesce算子控制最后的DataSet的分区数
  8.ods数据的保存格式？   lzop
  9.数仓各层级中，你主要负责哪些部分？ 全程负责
  10.azkaban除了任务调度还做了什么？  什么都干不了，还能报警
  11.任务失败除了重试和重跑，还做了什么？ 
  12.sqoop导数据的时候失败了怎么办？  从mysql导到hdfs，可以重跑，因为用的into overwrite ；从hdfs写到mysql, 

学长二：
  1.yarn调度器    FIFO；容量调度器（Apache默认容量）；公平调度器；（CDH里默认公平）
  2.问了好多linux命令 如何展示文件夹下文件个数  ls -l | grep "^-" | wc -l
  3.hive运行map数量过多，如何解决  
  4.hive数据倾斜 如何知道发生数据倾斜  yarn上看 
  5.hive大表join大表，如何避免数据倾斜，如何定位引起数据倾斜的key    可以采用分桶表，分桶字段和分桶数两个表都要一样。倾斜的key采用sample算子抽取然后使用countByKey算子进行定位，找出倾斜的key
  6.hive内部表、外部表区别，非要删外部表的元数据呢     alter table xxx set tblproperties ("EXTERNAL" = "FLASE")
  7.hive的集合数据类型      数组 、map 、结构体
  8.很长的脚本，里面的sql语句，如何定位错误发生在哪 
  9.介绍项目
  10.数仓如何保证维度的一致性    
  11.拉链表 几种实现方式
  12.分区表要增加字段怎么。  13.数据集市和数据仓库区别    数据集市是一种微型的数据仓库，通常有更少的数据，更少的主题，以及更少的历史数据，因此是部门级的。数仓是企业级的，能给企业各个部门提供决策手段n
  14.sql题 没截图 1连续获得冠军  2竖表转横表
  
学长三：
  1.hdfs,mr,yarn的理解
  2.mr的wordcount简单描述
  3.kafka快的原因，零拷贝的原理
  4.redis的数据类型
  5.kafka的isr队列
  6.spark的运行模式，wc的简单描述
  基本上是简历的东西
二面：
  基本上和简历无关，问的算法，我不懂，没办法整理
  
  
    
